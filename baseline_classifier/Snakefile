# This section build a neural net with motifs as filters
# And train a logistic classifier on the top of it
# Instead of training directly, it writes a training scripts that is ready to be submitted to cluster

def get_all_training_sbatch(config):
    out = []
    for i in config['Training']:
        out.append('sbatch/{motif_name}.{head}_{group}.train.sbatch'.format(motif_name=config['task_name'], head=config['type_of_head'], group=i))
    return out

rule all:
    input:
        files = get_all_training_sbatch(config)

rule assemble:
    input:
        motif = lambda wildcards: config[wildcards.motif_name]['motifs'],
        xtrain = lambda wildcards: config[wildcards.motif_name]['data']['train']['x'],
        xvalid = lambda wildcards: config[wildcards.motif_name]['data']['valid']['x'],
        ytrain = lambda wildcards: config[wildcards.motif_name]['data']['train']['y'],
        yvalid = lambda wildcards: config[wildcards.motif_name]['data']['valid']['y'],
    params:
        llr = lambda wildcards: config[wildcards.motif_name]['threshold'],
        background = lambda wildcards: config[wildcards.motif_name]['background']
    output:
        model = 'prototype/{motif_name}.init.hdf5',
        feature_train = 'data/{motif_name}.train.feature.hdf5',
        feature_valid = 'data/{motif_name}.valid.feature.hdf5'
    shell:
        '''python -u scripts/assemble.py --motif {input.motif} --xtrain {input.xtrain} --xvalid {input.xvalid}\
        --threshold {params.llr} --output {output.model} --background {params.background} \
        --output_train {output.feature_train} --output_valid {output.feature_valid} \
        --ytrain {input.ytrain} --yvalid {input.yvalid}'''

rule train:
    input:
        train = 'data/{motif_name}.train.feature.hdf5',
        valid = 'data/{motif_name}.valid.feature.hdf5'
    params:
        outfolder = lambda wildcards: 'train/{{motif_name}}.{headname}_{groupname}/'.format(headname=wildcards.head, groupname=wildcards.group),
        niter = lambda wildcards: config[wildcards.motif_name]['niter'],
        l1 = lambda wildcards: config['Training'][wildcards.group]['l1'],
        l2 = lambda wildcards: config['Training'][wildcards.group]['l2'],
        batch_size = 100, # lambda wildcards: config[wildcards.motif_name][''],
        partition = config['partition'],
        # head = config['type_of_head']
    output:
        'sbatch/{motif_name}.{head}_{group}.train.sbatch'
    run:
        sbatch = '''#!/bin/bash
#SBATCH --job-name={taskname}.{head}_{group}
#SBATCH --output={taskname}.{head}_{group}.out
#SBATCH --error={taskname}.{head}_{group}.err
#SBATCH --time=24:00:00
#SBATCH --partition={partition}
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --mem-per-cpu=50G
#SBATCH --nodes=1
#SBATCH --gres=gpu:1
cd /project2/xinhe/yanyul
source setup.sh
source activate deepvarpred_test
module load cuda/7.5
cd repo/deep_variant/baseline_classifier
mkdir {outdir}
python scripts/train_head_on_cluster.py \
--train {train} \
--valid {valid} \
--outdir {outdir} \
--batch_size {batch_size} \
--epoch {niter} \
--l1 {l1} \
--l2 {l2} \
--head {head}
'''.format(taskname=wildcards.motif_name, train=input.train, valid=input.valid,
niter=params.niter, batch_size=params.batch_size, outdir=params.outfolder,
l1=params.l1, l2=params.l2, group=wildcards.group, partition=params.partition,
head=wildcards.head)
        o = open(output[0], 'w')
        o.write(sbatch)
        o.close()

# The training is done by submitting a training script to cluster. The output is a collection of trained models along optimization.
# The best model is selected based on certain criteria, for instance, validation loss
# The final step is to combine feature extraction with selected logistic head as below

rule add_head:
    input:
        head = lambda wildcards: 'train/{motif_name}.{headname}_{head}'.format(motif_name=wildcards.motif_name, headname=wildcards.type_of_head, head=config['selected_head'][wildcards.head_name]),
        motif_feature = 'prototype/{motif_name}.init.hdf5'
    output:
        'model/{motif_name}_{type_of_head}.{head_name}.hdf5'
    shell:
        'python scripts/merge_body_and_head.py --body {input.motif_feature} --head {input.head} --out {output[0]}'
