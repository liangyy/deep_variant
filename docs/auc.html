<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Yanyu Liang" />


<title>AUC with imbalanced data</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-1.1/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Deep Variant</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Tasks</a>
</li>
<li>
  <a href="analysis_list.html">Analysis</a>
</li>
<li>
  <a href="memo_list.html">Technical Memo</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/liangyy/deep_variant">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">AUC with imbalanced data</h1>
<h4 class="author"><em>Yanyu Liang</em></h4>
<h4 class="date"><em>19 April, 2017</em></h4>

</div>


<style>
pre code, pre, code {
    white-space: pre !important;
    overflow-x: scroll !important;
    word-break: keep-all !important;
    word-wrap: initial !important;
}
</style>
<div id="motivation" class="section level1">
<h1><span class="header-section-number">1</span> Motivation</h1>
<p>Our data is highly imbalnced.</p>
<pre class="r"><code>library(ggplot2)
aucs &lt;- read.table(&#39;../data/aucs_informative.txt&#39;, sep = &#39;\t&#39;, header = T)
temp &lt;- read.table(&#39;../data/aucs.txt&#39;, sep = &#39;\t&#39;, header = T)
temp$DeepSEA.ROC.AUC &lt;- as.numeric(as.character(temp$DeepSEA.ROC.AUC ))</code></pre>
<pre><code>## Warning: NAs introduced by coercion</code></pre>
<pre class="r"><code>aucs$Proportion.True &lt;- read.table(&#39;../data/aucs_proportion_of_positive.txt&#39;, header = T)[!is.na(temp$DeepSEA.ROC.AUC),]
aucs$Wilcox.pvalue &lt;- read.table(&#39;../data/aucs_wilconx_pvalue.txt&#39;, header = T)[!is.na(temp$DeepSEA.ROC.AUC),]
ggplot(aucs) + geom_histogram(aes(x = Proportion.True), bins = 20) + facet_wrap(~ AnnotationType, scales = &#39;free&#39;)</code></pre>
<p><img src="auc_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<pre class="r"><code>ggplot(aucs) + geom_point(aes(x = Proportion.True, y = DeepSEA.ROC.AUC)) + facet_wrap(~ AnnotationType, scales = &#39;free&#39;) + ggtitle(&#39;Proportion of true label vs. ROC AUC&#39;)</code></pre>
<p><img src="auc_files/figure-html/unnamed-chunk-19-2.png" width="672" /></p>
<pre class="r"><code>ggplot(aucs) + geom_point(aes(x = Proportion.True, y = DeepSEA.PR.AUC)) + facet_wrap(~ AnnotationType, scales = &#39;free&#39;) + ggtitle(&#39;Proportion of true label vs. PR AUC&#39;)</code></pre>
<p><img src="auc_files/figure-html/unnamed-chunk-19-3.png" width="672" /></p>
<pre class="r"><code>ggplot(aucs) + geom_point(aes(x = Proportion.True, y = -log(Wilcox.pvalue))) + facet_wrap(~ AnnotationType, scales = &#39;free&#39;) + ggtitle(&#39;Proportion of true label vs. Wilcox pvalue&#39;) + scale_x_sqrt()</code></pre>
<p><img src="auc_files/figure-html/unnamed-chunk-19-4.png" width="672" /></p>
<pre class="r"><code>ggplot(aucs) + geom_point(aes(x = DeepSEA.ROC.AUC, y = -log(Wilcox.pvalue), color = log(Proportion.True))) + facet_wrap(~ AnnotationType, scales = &#39;free&#39;) + ggtitle(&#39;ROC AUC vs. Wilcox pvalue&#39;) + scale_x_sqrt()</code></pre>
<p><img src="auc_files/figure-html/unnamed-chunk-19-5.png" width="672" /></p>
<pre class="r"><code>ggplot(aucs) + geom_point(aes(x = DeepSEA.PR.AUC, y = -log(Wilcox.pvalue), color = log(Proportion.True))) + facet_wrap(~ AnnotationType, scales = &#39;free&#39;) + ggtitle(&#39;PR AUC vs. Wilcox pvalue&#39;) + scale_x_sqrt()</code></pre>
<p><img src="auc_files/figure-html/unnamed-chunk-19-6.png" width="672" /></p>
</div>
<div id="auc-interpretation" class="section level1">
<h1><span class="header-section-number">2</span> AUC interpretation</h1>
<p>Both ROC AUC and PR AUC are nonparametric statistics (rank based statistics). Consider a scoring function that tends to distinguish two groups. Then ideally, we want all of the samples in the true group have higher score than the ones in the false group.</p>
<p>Recall that ROC AUC is the area under TPR-FPR curve, where <span class="math inline">\(FPR = \frac{FP}{F}\)</span> and <span class="math inline">\(TPR = \frac{TP}{T}\)</span> and this quantity is <span class="math inline">\(\Pr(score^+ &gt; score^−)\)</span> if <span class="math inline">\(score^+\)</span> and <span class="math inline">\(score^−\)</span> are randomly seleted from the two groups. Additionally, PR AUC is the area under Precision-Recall curve, where <span class="math inline">\(Precision = \frac{TP}{P}\)</span> and <span class="math inline">\(Recall = \frac{TP}{T}\)</span>. If you think of an ordered sequence of balls with two colors (for two groups), every time you separate them into two parts, the purity of the part corresponds to precision and the proportion of a particular color in one part corresponds to the recall value.</p>
</div>
<div id="wilcox-pvalue" class="section level1">
<h1><span class="header-section-number">3</span> Wilcox pvalue</h1>
<p>Namely <a href="https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test">Mann–Whitney U test</a>. The null hypothesis is that two group has the same mean. But such null hypothesis may not be of great interest, because we may particularly want to increase sensitivity. It is somehow equivalent to permutation test where we simply permuate group labels.</p>
</div>
<div id="comparison-between-roc-and-pr" class="section level1">
<h1><span class="header-section-number">4</span> Comparison between ROC and PR</h1>
<p>This <a href="https://classeval.wordpress.com/">site</a> provides a comprehensive simulation analysis on the performance of ROC and PR as a measure of performance of binary classifier. Its results show that PR AUC is more informative than ROC AUC when the data is imbalanced. ROC AUC will stay the same while PR AUC changes dramatically. This is because ROC AUC only tells the property of two conditional distribution <span class="math inline">\(p(score|y = 1)\)</span> and <span class="math inline">\(p(score|y = 0)\)</span> but has nothing to do with the number of samples in each category. In our problem setting, however, ROC AUC as a measure is still informative and easy to interprete. This is because at test time the quantity of interest is the difference of <span class="math inline">\(score(ref)\)</span> and <span class="math inline">\(score(alt)\)</span>. So, we are more interested in the question that how well the scorescore can distinguish two very similar input sequences, in which case there is no imbalanced issue.</p>
<p>Therefore, the main issue caused by imbalanced data in our problem set up is at training phase. If the false labeled samples dominate the likelihood function (or loss function), the model will mainly work on decrease the likelihood or that part and does little on true labeled samples. An alternative loss function is to use hinge loss with weights to handle imbalanced data.</p>
</div>
<div id="simulation-analysis" class="section level1">
<h1><span class="header-section-number">5</span> Simulation analysis</h1>
<p>The following example illastrate the limitation of linear classifier, namely it is possible that linear classifier gives ROC AUC smaller than 0.5 under some hard to separate data sets.</p>
<pre class="r"><code>generate_wired_data &lt;- function(imbalance_ratio){
    nf &lt;- 10000
    nt &lt;- nf * imbalance_ratio
    temp &lt;- cbind(rnorm(nf), rnorm(nf))
    mat &lt;- matrix(c(2, 1, 1, 2), nrow = 2)
    false &lt;- temp %*% mat
    mix_ratio &lt;- 0.9
    temp2 &lt;- cbind(rep(1, nt * mix_ratio), rnorm(nt * mix_ratio), rnorm(nt * mix_ratio))
    mat2 &lt;- matrix(c(0.5, 1, 0.5, -0.5, 0.5, 1), ncol = 2)
    true_mix &lt;- temp2 %*% mat2 
    temp3 &lt;- cbind(rep(1, nt * (1 - mix_ratio)), rnorm(nt * (1 - mix_ratio)), rnorm(nt * (1 - mix_ratio)))
    mat3 &lt;- matrix(c(-15, 1, 0.5, 15, 0.5, 1), ncol = 2)
    true_outlier &lt;- temp3 %*% mat3
    data &lt;- list()
    data$x1 &lt;- c(false[,1], true_mix[,1], true_outlier[,1])
    data$x2 &lt;- c(false[,2], true_mix[,2], true_outlier[,2])
    data$label &lt;- c(rep(0, nrow(false)), rep(1, nrow(true_mix)), rep(1, nrow(true_outlier)))
    data$sublabel &lt;- c(rep(0, nrow(false)), rep(1, nrow(true_mix)), rep(2, nrow(true_outlier)))
    data &lt;- as.data.frame(data)
    return(data)
}
data &lt;- generate_wired_data(1)</code></pre>
<pre class="r"><code>library(precrec)
source(&#39;../../../mylib/my_r.R&#39;)
fit &lt;- glm(label~x1+x2,data=data,family=binomial())
summary(fit)</code></pre>
<pre><code>## 
## Call:
## glm(formula = label ~ x1 + x2, family = binomial(), data = data)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.306  -1.159  -1.046   1.217   1.286  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -0.043702   0.014358  -3.044  0.00234 ** 
## x1          -0.049400   0.005018  -9.844  &lt; 2e-16 ***
## x2           0.058493   0.005037  11.612  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 27725  on 19998  degrees of freedom
## Residual deviance: 27210  on 19996  degrees of freedom
## AIC: 27216
## 
## Number of Fisher Scoring iterations: 3</code></pre>
<pre class="r"><code>ggplot(data) + geom_point(aes(x = x1, y = x2, color = factor(label))) + ggtitle(&#39;Simulated data&#39;) + geom_abline(intercept = -fit$coefficients[1]/fit$coefficients[3], slope = -fit$coefficients[2]/fit$coefficients[3])</code></pre>
<p><img src="auc_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<pre class="r"><code>y_pred &lt;- predict(fit, type=&quot;response&quot;)
sscurves &lt;- evalmod(scores = y_pred, labels = data$label)
plot(sscurves)</code></pre>
<p><img src="auc_files/figure-html/unnamed-chunk-21-2.png" width="672" /></p>
<pre class="r"><code>report &lt;- list()
report$measure &lt;- c(&#39;ROC AUC&#39;, &#39;PR AUC&#39;, &#39;Accuracy&#39;, &#39;Precision.T&#39;, &#39;Precision.F&#39;, &#39;Recall.T&#39;, &#39;Recall.F&#39;, &#39;Proportion.T&#39;, &#39;Proportion.F&#39;)
report$value &lt;- c(auc(sscurves)$aucs, accuracy(data$label, y_pred), precision.t(data$label, y_pred), precision.f(data$label, y_pred), recall.t(data$label, y_pred), recall.f(data$label, y_pred), proportion.t(data$label), proportion.f(data$label))
print(as.data.frame(report))</code></pre>
<pre><code>##        measure     value
## 1      ROC AUC 0.3406749
## 2       PR AUC 0.4625028
## 3     Accuracy 0.4034202
## 4  Precision.T 0.2600596
## 5  Precision.F 0.4395542
## 6     Recall.T 0.1047105
## 7     Recall.F 0.7021000
## 8 Proportion.T 0.4999750
## 9 Proportion.F 0.5000250</code></pre>
<p>From the simulation you can see, if the feature space does not have enough distinguish power, the linear classifier will behave poorly (in term of ROC AUC) no matter whether the data set is imbalanced or not But it is good to note that imbalanced data set gives some misleadingly good results. For instance:</p>
<pre class="r"><code>data &lt;- generate_wired_data(0.02)
fit &lt;- glm(label~x1+x2,data=data,family=binomial())
summary(fit)</code></pre>
<pre><code>## 
## Call:
## glm(formula = label ~ x1 + x2, family = binomial(), data = data)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.2859  -0.2046  -0.1909  -0.1779   2.9596  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -3.99058    0.07432 -53.698  &lt; 2e-16 ***
## x1          -0.15171    0.02282  -6.647 2.98e-11 ***
## x2           0.13449    0.02316   5.806 6.40e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1960.9  on 10198  degrees of freedom
## Residual deviance: 1891.6  on 10196  degrees of freedom
## AIC: 1897.6
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<pre class="r"><code>ggplot(data) + geom_point(aes(x = x1, y = x2, color = factor(label))) + ggtitle(&#39;Simulated data&#39;) + geom_abline(intercept = -fit$coefficients[1]/fit$coefficients[3], slope = -fit$coefficients[2]/fit$coefficients[3])</code></pre>
<p><img src="auc_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<pre class="r"><code>y_pred &lt;- predict(fit, type=&quot;response&quot;)
sscurves &lt;- evalmod(scores = y_pred, labels = data$label)
plot(sscurves)</code></pre>
<p><img src="auc_files/figure-html/unnamed-chunk-22-2.png" width="672" /></p>
<pre class="r"><code>report &lt;- list()
report$measure &lt;- c(&#39;ROC AUC&#39;, &#39;PR AUC&#39;, &#39;Accuracy&#39;, &#39;Precision.T&#39;, &#39;Precision.F&#39;, &#39;Recall.T&#39;, &#39;Recall.F&#39;, &#39;Proportion.T&#39;, &#39;Proportion.F&#39;)
report$value &lt;- c(auc(sscurves)$aucs, accuracy(data$label, y_pred), precision.t(data$label, y_pred), precision.f(data$label, y_pred), recall.t(data$label, y_pred), recall.f(data$label, y_pred), proportion.t(data$label), proportion.f(data$label))
print(as.data.frame(report))</code></pre>
<pre><code>##        measure      value
## 1      ROC AUC 0.32399196
## 2       PR AUC 0.10772808
## 3     Accuracy 0.98235121
## 4  Precision.T 1.00000000
## 5  Precision.F 0.98231827
## 6     Recall.T 0.09547739
## 7     Recall.F 1.00000000
## 8 Proportion.T 0.01951172
## 9 Proportion.F 0.98048828</code></pre>
<p>Even if PR AUC decreases, the distinguish power or relative rank of the score remains equally good as the balanced case.</p>
</div>
<div id="weighted-hinge-loss-vs.vanilla-logistic-regression-on-imbalanced-data-set" class="section level1">
<h1><span class="header-section-number">6</span> Weighted hinge loss vs. vanilla logistic regression on imbalanced data set</h1>
<p>Here we show the performance of two loss functions on a simulated sequence data set. The goal is to see if it can improve the performance under the same number of iterations.</p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
