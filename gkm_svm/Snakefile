# This section build the pipeline to make prediction using gkm-SVM
# desribed in [this](https://github.com/Dongwon-Lee/lsgkm) repository

# The pipeline contains two part:
# 1. training: hdf5 -> fasta; training
# 2. prediction: hdf5 -> fasta; predicting
# due to the capability of the software, we may randomly select a
# subset of sequences to make prediction on

rule sampling_from_training_set:
    input:
        x = lambda wildcards: config['training_data']['x'][wildcards.trdata_name],
        y = lambda wildcards: config['training_data']['y'][wildcards.trdata_name]
    params:
        n = config['repeat'],
        prefix = lambda wildcards: 'data/{trdata_name}_{label}'.format(trdata_name=wildcards.trdata_name, label = wildcards.label),
        size = config['size'],
        seed = config['seed'],
        label = lambda wildcards: config['label'][wildcards.label]
    output:
        pos = temp([ 'data/{{trdata_name}}_{{label}}.{id}.pos.hdf5'.format(id=i+1) for i in range(config['repeat']) ]),
        neg = temp([ 'data/{{trdata_name}}_{{label}}.{id}.neg.hdf5'.format(id=i+1) for i in range(config['repeat']) ])
    shell:
        '''python scripts/split_training_set.py --x {input.x} \
        --y {input.y} --nsubset {params.n} \
        --prefix {params.prefix} --size {params.size} \
        --seed {params.seed} --label {params.label} '''

rule hdf5_to_fasta_valid:

rule hdf5_to_fasta_train:
    input:
        'data/{trdata_name}_{label}.{id}.{state}.hdf5'
    output:
        'data/{trdata_name}_{label}.{id}.{state}.fa'
    params:
        config['window_size']
    shell:
        'python scripts/hdf5_to_fasta.py --split 1 --window {params[0]} \
        --data {input[0]} --out {output[0]}'

#
# rule training:
#     input:
#     output:
#         'model/{model_name}_{id}.model.txt'
#
# rule prediction:
